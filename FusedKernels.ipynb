{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62bca490-d730-4aad-9cd9-1a7551ea2eae",
   "metadata": {},
   "source": [
    "# Fused Kernels - What started as exploring DLRM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be61622a-2bcb-4f93-910b-639e10d0b69f",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "\n",
    "Abstract: With focus on performance to get the most out of hardware, fusing of kernels has been a popular technique. At times, researchers/practitioners will re-write their code in native cuda or cpu kernels to get optimal performance, but projects such as torch.compile aim to make this simpler. Talk will focus on generating fused kernels and how to leverage torch.compile to be able to do that. We will shift a bit from all LLM talk and look into recommendation algorithms as big deep learning/AI systems. In the process, we will work on creating fused kernels (triton and cuda) with the help of torch.compile. \n",
    "\n",
    "## Code and other artifacts\n",
    "\n",
    "- Lecture code: https://github.com/kapilsh/cuda-mode-lecture\n",
    "- How to open chrome trace: chrome://tracing\n",
    "- DLRM Blog Post: https://ai.meta.com/blog/dlrm-an-advanced-open-source-deep-learning-recommendation-model/\n",
    "- DLRM Paper: https://arxiv.org/pdf/1906.00091\n",
    "- DLRM github repo: https://github.com/facebookresearch/dlrm\n",
    "- Criteo Dataset: https://ailab.criteo.com/download-criteo-1tb-click-logs-dataset/\n",
    "\n",
    "\n",
    "## DLRM (Deep Learning Recommendation Model)\n",
    "\n",
    "### MODEL ARCHITECTURE \n",
    "\n",
    "![DLRM Model](./data/dlrm_model.png)\n",
    "\n",
    "### System Constrants\n",
    "\n",
    "![System Constraints](./data/66324023_2056206621174067_2937830378620059648_n.gif)\n",
    "\n",
    "### Criteo Dataset\n",
    "\n",
    "- Training dataset with 24 days of ad display and click data (positive: clicked and negatives: non-clicked)\n",
    "- 13 features taking integer values (mostly count features)\n",
    "- 26 anonymized categorical features\n",
    "- Corresponding Kaggle competition: https://www.kaggle.com/c/criteo-display-ad-challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a8b063e1-6f04-4665-ac70-8508641d37b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "from typing import Mapping, List, Dict, Union\n",
    "\n",
    "import click\n",
    "import torch\n",
    "import torch._dynamo\n",
    "from loguru import logger\n",
    "from torch import nn, Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from criteo_dataset import CriteoParquetDataset\n",
    "from model import DenseArch, read_metadata, SparseArch, DenseSparseInteractionLayer, PredictionLayer, Parameters, DLRM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76eb45b-1ee6-4257-98a6-5185f57987a6",
   "metadata": {},
   "source": [
    "# Exploring DLRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1069bd19-a050-4c9b-8d1f-051e3bd7e319",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"./data/sample_criteo_data.parquet\"\n",
    "metadata_path = \"./data/sample_criteo_metadata.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42b72f15-8b72-4345-8d2f-a71ad4b8f01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-04 14:13:38.111 | INFO     | __main__:<module>:1 - Reading the parquet file ./data/sample_criteo_data.parquet...\n",
      "2024-05-04 14:13:38.113 | INFO     | __main__:<module>:2 - Reading the metadata file ./data/sample_criteo_metadata.json...\n",
      "2024-05-04 14:13:40.288 | INFO     | __main__:<module>:7 - Labels size: torch.Size([2])\n",
      "2024-05-04 14:13:40.288 | INFO     | __main__:<module>:8 - Dense size: torch.Size([2, 13])\n",
      "2024-05-04 14:13:40.289 | INFO     | __main__:<module>:9 - Sparse size: torch.Size([2, 26])\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Reading the parquet file {}...\".format(file_path))\n",
    "logger.info(\"Reading the metadata file {}...\".format(metadata_path))\n",
    "\n",
    "dataset = CriteoParquetDataset(file_path)\n",
    "data_loader = DataLoader(dataset, batch_size=2, shuffle=False)\n",
    "labels, dense, sparse = next(iter(data_loader))\n",
    "logger.info(\"Labels size: {}\".format(labels.size()))\n",
    "logger.info(\"Dense size: {}\".format(dense.size()))\n",
    "logger.info(\"Sparse size: {}\".format(sparse.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "884bc4d3-a489-45a1-b269-141db29a3b7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.0000e+00, 1.1000e+02, 0.0000e+00, 1.6000e+01, 0.0000e+00, 1.0000e+00,\n",
       "         0.0000e+00, 1.4000e+01, 7.0000e+00, 1.0000e+00, 0.0000e+00, 3.0600e+02,\n",
       "         0.0000e+00],\n",
       "        [3.2000e+01, 3.0000e+00, 5.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 6.1000e+01, 5.0000e+00, 0.0000e+00, 1.0000e+00, 3.1570e+03,\n",
       "         5.0000e+00]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c896c0f1-3773-4af5-bcc4-1aa1b17fb409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1651969401, 3793706328, 2951365679, 2489089999,  951068488, 1875733963,\n",
       "          897624609,  679512323, 1189011366,  771915201,  209470001, 2509774111,\n",
       "           12976055, 3192841527, 2316006604, 1289502458, 3523761834, 3088518074,\n",
       "         2501034507, 3280875304,  351689309,  632402057, 3619814411, 2091868316,\n",
       "          809724924, 3977271069],\n",
       "        [3857972621, 2695561126, 1873417685, 3666490401, 1020698403, 1875733963,\n",
       "         2870406529, 1128426537,  502653268, 2112471209, 1716706404, 2582335015,\n",
       "           12976055, 3192841527, 4089183897, 1289502458, 3523761834, 2716538129,\n",
       "         2501034507, 4273985635, 2737978529, 3370249814,  391309800, 1966410890,\n",
       "         2568167914, 3075991895]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e0476a3-0af3-4de7-985e-76a2f13d8da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-04 14:15:15.944 | INFO     | __main__:<module>:8 - Dense out size: torch.Size([2, 16])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ -15.9158,   -3.1166,  -14.7238,  -15.7895,    9.8099,   -7.4153,\n",
       "            6.1413,  -17.2388,  -17.7460,   36.3442,    9.2208,   17.1685,\n",
       "          -26.7153,    4.1549,  -27.6369,   13.1371],\n",
       "        [ -67.6642,  -24.3709, -192.2249, -123.3462,   86.3253,  -45.0116,\n",
       "          -26.8654, -194.2189, -240.2030,  305.7565,  136.9120,   46.5375,\n",
       "         -266.4658,   81.3118, -262.6347,  169.4223]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dense_mlp_out_size = 16\n",
    "num_dense_features = dense.size()[1]\n",
    "dense_arch = DenseArch(dense_feature_count=num_dense_features,\n",
    "                       dense_hidden_layers_sizes=[32],\n",
    "                       output_size=dense_mlp_out_size)\n",
    "dense_out = dense_arch(dense)\n",
    "logger.info(\"Dense out size: {}\".format(dense_out.size()))\n",
    "dense_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eca531ef-68ee-4773-821a-69518e3fed07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-04 14:16:50.027 | INFO     | __main__:<module>:13 - Sparse out size: torch.Size([2, 16])\n",
      "2024-05-04 14:16:50.027 | INFO     | __main__:<module>:13 - Sparse out size: torch.Size([2, 16])\n",
      "2024-05-04 14:16:50.028 | INFO     | __main__:<module>:13 - Sparse out size: torch.Size([2, 16])\n",
      "2024-05-04 14:16:50.028 | INFO     | __main__:<module>:13 - Sparse out size: torch.Size([2, 16])\n",
      "2024-05-04 14:16:50.028 | INFO     | __main__:<module>:13 - Sparse out size: torch.Size([2, 16])\n",
      "2024-05-04 14:16:50.029 | INFO     | __main__:<module>:13 - Sparse out size: torch.Size([2, 16])\n",
      "2024-05-04 14:16:50.029 | INFO     | __main__:<module>:13 - Sparse out size: torch.Size([2, 16])\n",
      "2024-05-04 14:16:50.029 | INFO     | __main__:<module>:13 - Sparse out size: torch.Size([2, 16])\n",
      "2024-05-04 14:16:50.030 | INFO     | __main__:<module>:13 - Sparse out size: torch.Size([2, 16])\n",
      "2024-05-04 14:16:50.030 | INFO     | __main__:<module>:13 - Sparse out size: torch.Size([2, 16])\n",
      "2024-05-04 14:16:50.031 | INFO     | __main__:<module>:13 - Sparse out size: torch.Size([2, 16])\n",
      "2024-05-04 14:16:50.032 | INFO     | __main__:<module>:13 - Sparse out size: torch.Size([2, 16])\n",
      "2024-05-04 14:16:50.032 | INFO     | __main__:<module>:13 - Sparse out size: torch.Size([2, 16])\n",
      "2024-05-04 14:16:50.033 | INFO     | __main__:<module>:13 - Sparse out size: torch.Size([2, 16])\n",
      "2024-05-04 14:16:50.033 | INFO     | __main__:<module>:13 - Sparse out size: torch.Size([2, 16])\n",
      "2024-05-04 14:16:50.033 | INFO     | __main__:<module>:13 - Sparse out size: torch.Size([2, 16])\n",
      "2024-05-04 14:16:50.034 | INFO     | __main__:<module>:13 - Sparse out size: torch.Size([2, 16])\n",
      "2024-05-04 14:16:50.034 | INFO     | __main__:<module>:13 - Sparse out size: torch.Size([2, 16])\n",
      "2024-05-04 14:16:50.035 | INFO     | __main__:<module>:13 - Sparse out size: torch.Size([2, 16])\n",
      "2024-05-04 14:16:50.035 | INFO     | __main__:<module>:13 - Sparse out size: torch.Size([2, 16])\n",
      "2024-05-04 14:16:50.036 | INFO     | __main__:<module>:13 - Sparse out size: torch.Size([2, 16])\n",
      "2024-05-04 14:16:50.037 | INFO     | __main__:<module>:13 - Sparse out size: torch.Size([2, 16])\n",
      "2024-05-04 14:16:50.037 | INFO     | __main__:<module>:13 - Sparse out size: torch.Size([2, 16])\n",
      "2024-05-04 14:16:50.038 | INFO     | __main__:<module>:13 - Sparse out size: torch.Size([2, 16])\n",
      "2024-05-04 14:16:50.038 | INFO     | __main__:<module>:13 - Sparse out size: torch.Size([2, 16])\n",
      "2024-05-04 14:16:50.038 | INFO     | __main__:<module>:13 - Sparse out size: torch.Size([2, 16])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0933, -0.0496,  0.7733, -1.7307, -1.5215, -1.7066, -1.0758, -1.0418,\n",
       "          0.0032,  0.9964,  0.9568, -3.0041,  1.6534, -1.3191,  1.5605, -0.5941],\n",
       "        [ 1.0211,  0.7705, -1.2030,  1.6011,  0.1957,  0.4547, -0.6117, -1.0417,\n",
       "         -0.7514, -0.2119,  0.4045, -0.3170,  0.4403, -1.0879,  0.8618, -0.3548]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "metadata = read_metadata(metadata_path)\n",
    "embedding_size = 16\n",
    "embedding_sizes = {fn: embedding_size for fn in metadata.keys()}\n",
    "sparse_mlp_out_size = 16\n",
    "sparse_arch = SparseArch(metadata=metadata,\n",
    "                         embedding_sizes=embedding_sizes)\n",
    "# compiled model hangs on running with inputs\n",
    "# sparse_arch_optim = torch.compile(sparse_arch)\n",
    "sparse_out = sparse_arch(sparse)\n",
    "for v in sparse_out:\n",
    "    logger.info(\"Sparse out size: {}\".format(v.size()))\n",
    "sparse_out[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "303ed5c6-d3f4-47b6-8ec4-02b1fd889444",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-04 14:18:34.244 | INFO     | __main__:<module>:3 - Dense sparse interaction out size: torch.Size([2, 186624])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.5331e+02,  4.9603e+01,  2.3434e+02,  ..., -2.1245e+00,\n",
       "          2.2212e-01,  9.8313e-01],\n",
       "        [ 4.5784e+03,  1.6490e+03,  1.3007e+04,  ...,  3.6353e-03,\n",
       "          7.7478e-03,  2.5760e-04]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_sparse_interaction_layer = DenseSparseInteractionLayer()\n",
    "ds_out = dense_sparse_interaction_layer(dense_out, sparse_out)\n",
    "logger.info(\"Dense sparse interaction out size: {}\".format(ds_out.size()))\n",
    "ds_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "965bb04a-8025-4398-8924-7e2d7b1e857e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-04 14:33:00.571 | INFO     | __main__:<module>:5 - Prediction out size: torch.Size([2, 1])\n",
      "2024-05-04 14:33:00.572 | INFO     | __main__:<module>:6 - Prediction out value: tensor([[0.9976],\n",
      "        [1.0000]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "prediction_layer = PredictionLayer(dense_out_size=dense_mlp_out_size,\n",
    "                                   sparse_out_sizes=[sparse_mlp_out_size] * len(metadata),\n",
    "                                   hidden_sizes=[16])\n",
    "pred_out = prediction_layer(ds_out)\n",
    "logger.info(\"Prediction out size: {}\".format(pred_out.size()))\n",
    "logger.info(\"Prediction out value: {}\".format(pred_out))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e291be4b-6e30-4ba1-aedb-5b54cba4feeb",
   "metadata": {},
   "source": [
    "## Model Graph\n",
    "\n",
    "![Model Graph](./data/model_graph.png)\n",
    "\n",
    "## Profiling\n",
    "\n",
    "### Initial Setup: Simple 2 layered MLP used for each triangle\n",
    "\n",
    "### Baseline\n",
    "\n",
    "> python model_train.py\n",
    "\n",
    "### Initial Distribution - Naive Implementation of index_hash\n",
    "\n",
    "![Initial index](./perf_screenshots/pytorch_profile_initial_index_hash.png)\n",
    "\n",
    "> tensorboard --logdir tb_logs --bind_all\n",
    "\n",
    "![Summary Initial](./perf_screenshots/summary_initial_index_hash.png)\n",
    "\n",
    "- What's going on - what is _local_scalar_dense and why is item() taking so long?\n",
    "\n",
    "> CUDA_LAUNCH_BLOCKING=1\n",
    "\n",
    "![Summary Initial](./perf_screenshots/summary_initial_cuda_launch_blocking.png)\n",
    "\n",
    "![Initial Index Hash Profile](./perf_screenshots/index_hash_profile_1.png)\n",
    "\n",
    "![Index Hash After Improvement](./perf_screenshots/improve_index_hash.png)\n",
    "\n",
    "- Index hash seems pretty expensive\n",
    "- Not adaptive to new sparse ids\n",
    "- Can we improve/simplify the hash function\n",
    "- Let's just calculate the modulus hash based on cardinality\n",
    "\n",
    "![Naive Modulus Hash](./perf_screenshots/naive_modulus_hash.png)\n",
    "\n",
    "- Let's check the time it took for each of the previous versions\n",
    "- Wall time down from 48ms -> 5ms\n",
    "\n",
    "![Optimized Modulus Hash](./perf_screenshots/optimized_modulus_hash.png)\n",
    "\n",
    "- Down to 3.48ms\n",
    "\n",
    "Based on the profile, what could be the next thing to look at?\n",
    "\n",
    "- index_select?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbdc60a-5d38-4fd8-8498-3f9a7f283220",
   "metadata": {},
   "source": [
    "# torch.compile\n",
    "\n",
    "##  torch.compile DLRM\n",
    "\n",
    "> TORCH_COMPILE_DEBUG_DIR=/home/ksharma/logs TORCH_LOGS=recompiles,+dynamo,inductor,guards,graph_breaks python model.py\n",
    "\n",
    "> CUDA_LAUNCH_BLOCKING=1 python model_train.py\n",
    "\n",
    "- GPU utilization goes up\n",
    "- memory footprint goes down\n",
    "\n",
    "\n",
    "### Pre `torch.compile`\n",
    "![Pre torch.compile](./perf_screenshots/pre_torch_compile_initial.png)\n",
    "\n",
    "### Post `torch.compile`\n",
    "![Post torch.compile](./perf_screenshots/post_torch_compile_initial.png)\n",
    "\n",
    "### Chrome Trace after `torch.compile`\n",
    "![Chrome Trace](./perf_screenshots/pytorch_profile_torch_compile.png)\n",
    "\n",
    "### Let's look deeper into what's going on\n",
    "\n",
    "![torch compile triton kernels](./perf_screenshots/torch_compile_triton_kernels.png)\n",
    "\n",
    "### Increase complexity\n",
    "\n",
    "Source: \n",
    "\n",
    "```shell\n",
    "python dlrm_s_pytorch.py --arch-sparse-feature-size=16 --arch-mlp-bot=\"13-512-256-64-16\" --arch-mlp-top=\"512-256-1\" --data-generation=dataset --data-set=kaggle --processed-data-file=./input/kaggle_processed.npz --loss-function=bce --round-targets=True --learning-rate=0.1 --mini-batch-size=128 --print-freq=1024 --print-time\n",
    "```\n",
    "\n",
    "- --arch-mlp-bot=\"13-512-256-64-16\"\n",
    "- --arch-mlp-top=\"512-256-1\"\n",
    "\n",
    "### Eager view\n",
    "\n",
    "![Full Model Eager View](./perf_screenshots/full_model_eager_view.png)\n",
    "\n",
    "- Sparse Arch is now not the biggest piece of the pie\n",
    "\n",
    "### torch compiled view\n",
    "\n",
    "![Full Model Torch Compiled](./perf_screenshots/full_model_torch_compiled.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19abe6a3-74fa-47b8-b439-1b4af946ffa0",
   "metadata": {},
   "source": [
    "# torch.compile -> triton code generation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36a3a34-b9c9-44cf-9b84-3757477bdf81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "87661f85-04e4-4649-acb4-4a19061d8f05",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f9d6ad-c572-44da-944a-8e11a875d477",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
